{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANCE_DB_LOC = \"/code/rag-gain/.lancedb\"\n",
    "LANCE_DB_TABLENAME = \"all-mpnet-base-v2_384\"\n",
    "SENTS_EMBEDDER_MODEL = \"all-mpnet-base-v2\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect(LANCE_DB_LOC)\n",
    "table = db.open_table(LANCE_DB_TABLENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Vector DB, similarity search\n",
    "\n",
    "First retrieve rough search of 20 closest vectors to query embedding;\n",
    "\n",
    "Then rerank using cross-encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model = SentenceTransformer(SENTS_EMBEDDER_MODEL, device=\"cpu\")\n",
    "def search(query, top_k = 20):\n",
    "    \"\"\"\n",
    "    Search query in table\n",
    "    args:\n",
    "        query : str\n",
    "        top_k : int\n",
    "\n",
    "    return : pd.DataFrame\n",
    "    \"\"\"\n",
    "    query_vector = query_model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "    search_results = table.search(query_vector).limit(top_k)\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_examples_for_test =  [\" * Rules on artificial intelligence in healthcare\\n\",\n",
    "                            \" * Artificial intelligence in agriculture\\n\",\n",
    "                            \" * Policies in data privacy\\n\",\n",
    "                            \" * AI and labour market\\n\"]\n",
    "\n",
    "print(\"[EXAMPLES]:\\n\")\n",
    "for query in query_examples_for_test:\n",
    "    print(query)\n",
    "\n",
    "print(\"[QUERY]: Enter query to vector DB ->\\n\")\n",
    "query = str(input())\n",
    "print(f\"[USER QUERY]:\\n{query}\\n\")\n",
    "\n",
    "search_results = search(query, top_k = 20).to_pandas().dropna(subset = \"text\").reset_index(drop=True)\n",
    "print(f\"[Vector DB search]:\\n\")\n",
    "for t in range(len(search_results.text)):\n",
    "    print(search_results.text[t])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(query, top_k = 20).to_pandas().dropna(subset = \"text\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[\"old_similarity_rank\"] = search_results.sort_values(\"_distance\", ascending=False).index+1\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerank\n",
    "Use rought search from previous step and rerank query with each of topK results with heavy cross-encoder (more precise pair reranking), return top K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "reranker_model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "cross_encoder_model = CrossEncoder(reranker_model_name, device=\"cuda\")\n",
    "\n",
    "def rerank(query, search_results, K : int = 5):\n",
    "    \"\"\"\n",
    "    Rerank search results\n",
    "    args:\n",
    "        query : str - query\n",
    "        search_results : pd.DataFrame - vector search results\n",
    "        K : int - number of reranked results\n",
    "\n",
    "    return : pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    query_retrieve_comb = [[query, sent] for sent in search_results[\"text\"]]\n",
    "    search_results[\"_distance_reranked\"] = cross_encoder_model.predict(query_retrieve_comb, activation_fct=torch.nn.Sigmoid())\n",
    "    topk = search_results.sort_values(\"_distance_reranked\", ascending=False).head(K)\n",
    "    return topk\n",
    "\n",
    "new_df = rerank(query, search_results)\n",
    "\n",
    "print(f\"[Reranked Vector DB search]:\\n\")\n",
    "\n",
    "for t in new_df.text:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
